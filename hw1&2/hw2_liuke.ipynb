{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "  for l in urlopen(fname):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "  feat = [1, datum['review/taste'], datum['review/appearance'], \\\n",
    "          datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "  return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "  return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "      loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data)\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:len(X)//3]     # top 1/3 of the shuffled data\n",
    "y_train = y[:len(y)//3]\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "  return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta,X,Y):\n",
    "  scores = [inner(theta,x) for x in X]\n",
    "  predictions = [s > 0 for s in scores]\n",
    "  correct = [(a == b) for (a,b) in zip(predictions,Y)]\n",
    "  acc = sum(correct) * 1.0 / len(correct)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy of the training set=0.7224888995559823\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "### training set\n",
    "lam = 1.0\n",
    "\n",
    "theta = train(lam)\n",
    "acc = performance(theta,X_train,y_train)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy of the training set=\" + str(acc))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy of the validation set=0.7171656566868663\n"
     ]
    }
   ],
   "source": [
    "### validation set\n",
    "\n",
    "X_validation=X[len(X)//3:2*len(X)//3]\n",
    "y_validation=y[len(y)//3:2*len(y)//3]\n",
    "acc1 = performance(theta,X_validation,y_validation)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy of the validation set=\" + str(acc1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 1.0:\taccuracy of the validation set=0.7178856422871542\n"
     ]
    }
   ],
   "source": [
    "### test set\n",
    "\n",
    "X_test=X[2*len(X)//3:]\n",
    "y_test=y[2*len(y)//3:]\n",
    "acc2 = performance(theta,X_test,y_test)\n",
    "print(\"lambda = \" + str(lam) + \":\\taccuracy of the validation set=\" + str(acc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of predicted positives:\t12350\n",
      "The number of predicted negatives:\t4317\n",
      "The number of True Positives:\t9038\n",
      "The number of True Negatives:\t2927\n",
      "The number of False Positives:\t3312\n",
      "The number of False Negatives:\t1390\n"
     ]
    }
   ],
   "source": [
    "### P/N/TP/TN/FP/FN of the test set \n",
    "scores2 = [inner(theta,x) for x in X_test]\n",
    "predictions2 = [s > 0 for s in scores2]\n",
    "\n",
    "###  positives\n",
    "nums_positive = sum(predictions2)\n",
    "print(\"The number of predicted positives:\\t\" + str(nums_positive))\n",
    "\n",
    "### negatives\n",
    "nums_negative = len(predictions2)-nums_positive\n",
    "print(\"The number of predicted negatives:\\t\" + str(nums_negative))\n",
    "\n",
    "### True Positives\n",
    "TP = [(a == b and a == True) for (a,b) in zip(predictions2,y_test)]\n",
    "nums_TP = sum(TP)\n",
    "print(\"The number of True Positives:\\t\" + str(nums_TP))\n",
    "\n",
    "### True Negatives\n",
    "TN = [(a == b and a == False) for (a,b) in zip(predictions2,y_test)]\n",
    "nums_TN = sum(TN)\n",
    "print(\"The number of True Negatives:\\t\" + str(nums_TN))\n",
    "\n",
    "### False Positives\n",
    "FP = [(a == True and b == False) for (a,b) in zip(predictions2,y_test)]\n",
    "nums_FP = sum(FP)\n",
    "print(\"The number of False Positives:\\t\" + str(nums_FP))\n",
    "\n",
    "### False Negatives\n",
    "FN = [(a == False and b == True) for (a,b) in zip(predictions2,y_test)]\n",
    "nums_FN = sum(FN)\n",
    "print(\"The number of False Negatives:\\t\" + str(nums_FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to assign greater importance to False Positives as compared to False Negatives, <br>\n",
    " we could reduce the likelihood of FP, that is, case y>0 and logit<0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "# NEGATIVE Log-likelihood\n",
    "def f_weighted(theta, X, y, lam):\n",
    "  loglikelihood = 0\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    loglikelihood -= log(1 + exp(-logit))\n",
    "    if not y[i]:\n",
    "        if logit>0 :\n",
    "            loglikelihood -= logit*1.4  ## modified place\n",
    "          #  loglikelihood *= 10\n",
    "        else :\n",
    "            loglikelihood -= logit\n",
    "  for k in range(len(theta)):\n",
    "    loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "  return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime_weighted(theta, X, y, lam):\n",
    "  dl = [0]*len(theta)\n",
    "  for i in range(len(X)):\n",
    "    logit = inner(X[i], theta)\n",
    "    for k in range(len(theta)):\n",
    "      dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "      if not y[i]:\n",
    "        if logit >0 :\n",
    "           dl[k] -= X[i][k]*1.4\n",
    "         #  dl[k] *= 10\n",
    "        else :\n",
    "           dl[k] -= X[i][k]\n",
    "  for k in range(len(theta)):\n",
    "    dl[k] -= lam*2*theta[k]\n",
    "  return numpy.array([-x for x in dl])\n",
    "\n",
    "def train_weighted(lam):\n",
    "  theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f_weighted, [0]*len(X[0]), fprime_weighted, pgtol = 10, \\\n",
    "                                           args = (X_train, y_train, lam))\n",
    "  return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of True Positives:\t8418\n",
      "The number of True Negatives:\t3634\n",
      "The number of False Positives:\t2605\n",
      "The number of False Negatives:\t2010\n"
     ]
    }
   ],
   "source": [
    "theta1 = train_weighted(lam)\n",
    "scores_weighted = [inner(theta1,x) for x in X_test]\n",
    "predictions_weighted = [s > 0 for s in scores_weighted]\n",
    "\n",
    "### True Positives\n",
    "TP1 = [(a == b and a == True) for (a,b) in zip(predictions_weighted,y_test)]\n",
    "nums_TP1 = sum(TP1)\n",
    "print(\"The number of True Positives:\\t\" + str(nums_TP1))\n",
    "\n",
    "### True Negatives\n",
    "TN1 = [(a == b and a == False) for (a,b) in zip(predictions_weighted,y_test)]\n",
    "nums_TN1 = sum(TN1)\n",
    "print(\"The number of True Negatives:\\t\" + str(nums_TN1))\n",
    "\n",
    "### False Positives\n",
    "FP1 = [(a == True and b == False) for (a,b) in zip(predictions_weighted,y_test)]\n",
    "nums_FP1 = sum(FP1)\n",
    "print(\"The number of False Positives:\\t\" + str(nums_FP1))\n",
    "\n",
    "### False Negatives\n",
    "FN1 = [(a == False and b == True) for (a,b) in zip(predictions_weighted,y_test)]\n",
    "nums_FN1 = sum(FN1)\n",
    "print(\"The number of False Negatives:\\t\" + str(nums_FN1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0:\taccuracy of the validation set=0.7177056458870823\n",
      "lambda = 0.01:\taccuracy of the validation set=0.7177056458870823\n",
      "lambda = 0.1:\taccuracy of the validation set=0.7177656446871062\n",
      "lambda = 1:\taccuracy of the validation set=0.7171656566868663\n",
      "lambda = 100:\taccuracy of the validation set=0.6693466130677387\n"
     ]
    }
   ],
   "source": [
    "#### lam = 0\n",
    "theta_0 = train(0)\n",
    "acc_0 = performance(theta_0,X_validation,y_validation)\n",
    "print(\"lambda = \" + str(0) + \":\\taccuracy of the validation set=\" + str(acc_0))  \n",
    "\n",
    "### lam = 0.01\n",
    "theta_1 = train(0.01)\n",
    "acc_1 = performance(theta_1,X_validation,y_validation)\n",
    "print(\"lambda = \" + str(0.01) + \":\\taccuracy of the validation set=\" + str(acc_1)) \n",
    "\n",
    "### lam = 0.1\n",
    "theta_2 = train(0.1)\n",
    "acc_2 = performance(theta_2,X_validation,y_validation)\n",
    "print(\"lambda = \" + str(0.1) + \":\\taccuracy of the validation set=\" + str(acc_2)) \n",
    "\n",
    "### lam = 1\n",
    "theta_3 = train(1)\n",
    "acc_3 = performance(theta_3,X_validation,y_validation)\n",
    "print(\"lambda = \" + str(1) + \":\\taccuracy of the validation set=\" + str(acc_3)) \n",
    "\n",
    "### lam = 100\n",
    "theta_4 = train(100)\n",
    "acc_4 = performance(theta_4,X_validation,y_validation)\n",
    "print(\"lambda = \" + str(100) + \":\\taccuracy of the validation set=\" + str(acc_4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best $\\lambda$ is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 100:\taccuracy of the train set=0.6740669626785072\n",
      "lambda = 100:\taccuracy of the test set=0.5965438617544702\n"
     ]
    }
   ],
   "source": [
    "acc_train = performance(theta_4,X_train,y_train)\n",
    "print(\"lambda = \" + str(100) + \":\\taccuracy of the train set=\" + str(acc_train))\n",
    "acc_test = performance(theta_4,X_test,y_train)\n",
    "print(\"lambda = \" + str(100) + \":\\taccuracy of the test set=\" + str(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Network visualization ###\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = set()\n",
    "nodes = set()\n",
    "for edge in urlopen(\"http://jmcauley.ucsd.edu/cse258/data/facebook/egonet.txt\"):\n",
    "  x,y = edge.split()\n",
    "  x,y = int(x),int(y)\n",
    "  edges.add((x,y))\n",
    "  edges.add((y,x))\n",
    "  nodes.add(x)\n",
    "  nodes.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "  G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The number of connected components:\t3\n",
      "The largest component's node number\t40\n"
     ]
    }
   ],
   "source": [
    "### define a dict :group  [ key: node i; value: all node j if (i,j) in edges]\n",
    "group={}   \n",
    "for edge in edges :\n",
    "    if edge[0] in group :\n",
    "        group[edge[0]].add(edge[1])\n",
    "    else :\n",
    "        group[edge[0]]=set([edge[1]])\n",
    "\n",
    "\n",
    "### use BFS to find all nodes that belongs to one group\n",
    "def get_all_connected_groups(graph):\n",
    "    already_seen = set()\n",
    "    result = []\n",
    "    for node in graph:\n",
    "        if node not in already_seen:\n",
    "            connected_group, already_seen = \\\n",
    "            get_connected_group(graph,node, already_seen)\n",
    "            result.append(connected_group)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_connected_group(graph,node, already_seen):\n",
    "        result = []\n",
    "        nodes = set([node])\n",
    "        while nodes:\n",
    "            node = nodes.pop()\n",
    "            already_seen.add(node)\n",
    "            nodes.update(graph[node] - already_seen) \n",
    "            result.append(node)\n",
    "        return result, already_seen\n",
    "\n",
    "components = get_all_connected_groups(group)\n",
    "#print(components)\n",
    "\n",
    "print(\"\\n The number of connected components:\\t\" +str(len(components)))\n",
    "length = [0]*len(components)\n",
    "for i in range(len(components)):\n",
    "    length[i] = len(components[i])\n",
    "print(\"The largest component's node number\\t\"+str(max(length)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized cut cost is: 0.42240587695133147\n"
     ]
    }
   ],
   "source": [
    "### new_graph is the largest connected component\n",
    "new_graph = components[0]\n",
    "new_graph.sort()\n",
    "\n",
    "### split new_graph into two parts\n",
    "graph1 = new_graph[:len(new_graph)//2]\n",
    "graph2 = new_graph[len(new_graph)//2:]\n",
    "\n",
    "### find the normalized cut\n",
    "def norm_cut(graph1,graph2) :\n",
    "    cut = 0\n",
    "    degree1 = sum(G.degree(node1) for node1 in graph1)\n",
    "    degree2 = sum(G.degree(node2) for node2 in graph2)\n",
    "    for node1 in graph1 :\n",
    "       for node2 in graph2 :\n",
    "          if (node1,node2) in edges:\n",
    "              cut+=1\n",
    "    Norm_cut=0.5 * (cut/degree1 + cut/degree2)\n",
    "    return Norm_cut\n",
    "res = norm_cut(graph1,graph2)\n",
    "print(\"The normalized cut cost is: \"+ str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized cut cost is 0.09817045961624274\n",
      "nodes in Community 1: [697, 703, 708, 713, 719, 745, 747, 753, 769, 772, 774, 800, 803, 805, 810, 811, 819, 828, 823, 830, 840, 880, 890, 869, 856]\n",
      "nodes in Community 2: [825, 861, 863, 864, 876, 878, 882, 884, 886, 888, 889, 893, 729, 804, 798]\n"
     ]
    }
   ],
   "source": [
    "# minimize the cost, if new generated cost is higher than the \n",
    "# previous one, then stop\n",
    "\n",
    "old_min_cost = res\n",
    "new_min_cost = res\n",
    "while True :\n",
    "    if old_min_cost < new_min_cost :\n",
    "        break\n",
    "    else :\n",
    "        old_min_cost = new_min_cost\n",
    "        \n",
    "    cost = [0] * len(new_graph)\n",
    "    for i in range(len(new_graph)) :\n",
    "      g1= graph1.copy()\n",
    "      g2= graph2.copy()\n",
    "      if new_graph[i] in g1 :\n",
    "          g2 += [new_graph[i]]\n",
    "          del g1[g1.index(new_graph[i])]\n",
    "      else :\n",
    "          g1 += [new_graph[i]]\n",
    "          del g2[g2.index(new_graph[i])]\n",
    "      cost[i] = norm_cut (g1, g2)\n",
    "    \n",
    "    move_point = cost.index(min(cost))\n",
    "\n",
    "    if new_graph[move_point] in graph1 :\n",
    "       graph2 += [new_graph[move_point]]\n",
    "       del graph1[graph1.index(new_graph[move_point])]\n",
    "    else :\n",
    "       graph1 += [new_graph[move_point]]\n",
    "       del graph2[graph2.index(new_graph[move_point])]\n",
    "    new_min_cost =  min(cost)\n",
    "\n",
    "print(\"The normalized cut cost is \"+str(old_min_cost))\n",
    "print(\"nodes in Community 1: \"+str(graph1))\n",
    "print(\"nodes in Community 2: \"+str(graph2))\n",
    "\n",
    "### because the content is cut when saving as PDF,\n",
    "### I will show the result in annotation\n",
    "### community 1:[697, 703, 708, 713, 719, 745, 747, 753, 769, 772, 774,\n",
    "### 800, 803, 805, 810, 811, 819, 828, 823, 830, 840, 880, 890, 869, 856]\n",
    "### community 2: [825, 861, 863, 864, 876, 878, 882, 884, \n",
    "### 886, 888, 889, 893, 729, 804, 798]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 1:[697, 703, 708, 713, 719, 745, 747, 753, 769, 772, 774, 800, 803, 805, 810, 811, 819, 828, 823, 830, 840, 880, 890, 869, 856]\n",
      "Community 2:[825, 861, 863, 864, 876, 878, 882, 884, 886, 888, 889, 893, 729, 804, 798]\n",
      "modularity values for the split: 0.3380165289256196\n"
     ]
    }
   ],
   "source": [
    "## new_graph : 40 nodes : a connected tcommunity\n",
    "## all_edge : number of edges in the new_graph\n",
    "all_edge = sum([G.degree(v) for v in new_graph])/2\n",
    "#print(all_edge)\n",
    "\n",
    "## split into two parts\n",
    "graph_1 = new_graph[:len(new_graph)//2]\n",
    "graph_2 = new_graph[len(new_graph)//2:]\n",
    "\n",
    "### compute Q\n",
    "def q(all_edge, g1, g2):\n",
    "    count =0\n",
    "    for i in g1 :\n",
    "        for j in g2 :\n",
    "            if (i,j) in edges :\n",
    "              count += 1\n",
    "    q_=(all_edge-count)/all_edge\n",
    "    a = sum([G.degree(v) for v in g1])\n",
    "    q_ -= (a/(all_edge*2))**2\n",
    "    a = sum([G.degree(v) for v in g2])\n",
    "    q_ -= (a/(all_edge*2))**2\n",
    "    return q_\n",
    "\n",
    "### Greedy algorithm , when new Q is not increasing, stop.\n",
    "old_q = new_q = -0.5\n",
    "while True :\n",
    "    if old_q > new_q :\n",
    "        break\n",
    "    else :\n",
    "        old_q = new_q\n",
    "        \n",
    "    q_list = [0] * len(new_graph)\n",
    "    for i in range(len(new_graph)) :\n",
    "       g1 = graph_1.copy()\n",
    "       g2 = graph_2.copy()\n",
    "       if new_graph[i] in g1 :\n",
    "          g2 += [new_graph[i]]\n",
    "          del g1[g1.index(new_graph[i])]\n",
    "       else :\n",
    "          g1 += [new_graph[i]]\n",
    "          del g2[g2.index(new_graph[i])]\n",
    "       q_list[i] = q(all_edge, g1, g2)\n",
    "    \n",
    "    mp= q_list.index(max(q_list))\n",
    "    if new_graph[mp] in graph_1 :\n",
    "       graph_2 += [new_graph[mp]]\n",
    "       del graph_1[graph_1.index(new_graph[mp])]\n",
    "    else :\n",
    "       graph_1 += [new_graph[mp]]\n",
    "       del graph_2[graph_2.index(new_graph[mp])]\n",
    "    new_q = max(q_list)\n",
    "print(\"Community 1:\"+str(graph1))\n",
    "print(\"Community 2:\"+str(graph2))\n",
    "print(\"modularity values for the split: \"+str(old_q))\n",
    "\n",
    "### the two community we found here is the same with that in Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
